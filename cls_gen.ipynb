{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "current: 0.81\n",
      "\n",
      "## TODO\n",
      "1. Retry with new more data # BEFORE: 0.70\n",
      "3. (Advanced) LSH/Shingle/MinHash and other ANN (http://nearpy.io/) - chapter 3.4.3 of Mining Massive Dataset\n",
      "3. (ADVANCED) LSA (SVD)\n",
      "4. (EXTRA ADVANCED) KMeans on word2vec"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load Data\n",
      "import cPickle as pickle\n",
      "\n",
      "x_list = []\n",
      "y_list = []\n",
      "\n",
      "neg = pickle.load(open('pickled/neg.feats', 'rb'))\n",
      "pos = pickle.load(open('pickled/pos.feats', 'rb'))\n",
      "\n",
      "x_list.extend(neg)\n",
      "y_list.extend([0] * len(neg))\n",
      "x_list.extend(pos)\n",
      "y_list.extend([1] * len(pos))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Simple Cross Val\n",
      "from sklearn import cross_validation\n",
      "from sklearn import svm\n",
      "from sklearn import linear_model\n",
      "\n",
      "\n",
      "clf = svm.SVC(kernel='linear', C=10)\n",
      "scores = cross_validation.cross_val_score(clf, x_list, y_list, cv=10, n_jobs=-1)\n",
      "\n",
      "print(scores)\n",
      "import numpy as np\n",
      "print(np.mean(scores))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Grid Search on precision_score\n",
      "from __future__ import print_function\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.metrics import classification_report\n",
      "from sklearn.metrics import confusion_matrix, precision_score, make_scorer\n",
      "\n",
      "from sklearn.svm import SVC\n",
      "\n",
      "\n",
      "# Split the dataset in two equal parts\n",
      "X_train, X_test, y_train, y_test = train_test_split(\n",
      "    x_list, y_list, test_size=0.5, random_state=0)\n",
      "\n",
      "# Set the parameters by cross-validation\n",
      "tuned_parameters = [{'C': [10], 'class_weight':[{1:0.6}]}]\n",
      "\n",
      "scorer = make_scorer(precision_score, labels=[0, 1], pos_label=1)\n",
      "\n",
      "clf = GridSearchCV(SVC(), tuned_parameters, cv=5, scoring=scorer, n_jobs=-1)\n",
      "clf.fit(X_train, y_train)\n",
      "\n",
      "print(\"Best parameters set found on development set:\")\n",
      "print()\n",
      "print(clf.best_estimator_)\n",
      "print()\n",
      "print(\"Grid scores on development set:\")\n",
      "print()\n",
      "for params, mean_score, scores in clf.grid_scores_:\n",
      "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean_score, scores.std() / 2.0, params))\n",
      "print('\\n\\n')\n",
      "\n",
      "print(\"Detailed classification report:\")\n",
      "print()\n",
      "print(\"The model is trained on the full development set.\")\n",
      "print(\"The scores are computed on the full evaluation set.\")\n",
      "print()\n",
      "y_true, y_pred = y_test, clf.predict(X_test)\n",
      "print(classification_report(y_true, y_pred))\n",
      "print()\n",
      "\n",
      "print(\"Confusion Matrix\")\n",
      "cm = confusion_matrix(y_test, y_pred)\n",
      "print(cm)\n",
      "print()\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "# Show confusion matrix in a separate window\n",
      "#plt.matshow(cm)\n",
      "#plt.title('Confusion matrix')\n",
      "#plt.colorbar()\n",
      "#plt.ylabel('True label')\n",
      "#plt.xlabel('Predicted label')\n",
      "#plt.show()\n",
      "\n",
      "s = '''\n",
      "SVC(C=10, class_weight={1:0.2})\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Best parameters set found on development set:\n",
        "\n",
        "SVC(C=10, cache_size=200, class_weight={1: 0.8}, coef0=0.0, degree=3,\n",
        "  gamma=0.0, kernel='rbf', max_iter=-1, probability=False,\n",
        "  random_state=None, shrinking=True, tol=0.001, verbose=False)\n",
        "\n",
        "Grid scores on development set:\n",
        "\n",
        "0.939 (+/-0.003) for {'C': 10, 'class_weight': {1: 0.8}}\n",
        "\n",
        "\n",
        "\n",
        "Detailed classification report:\n",
        "\n",
        "The model is trained on the full development set.\n",
        "The scores are computed on the full evaluation set.\n",
        "\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.74      0.96      0.84      8190\n",
        "          1       0.94      0.66      0.78      7996\n",
        "\n",
        "avg / total       0.84      0.81      0.81     16186\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Confusion Matrix\n",
        "[[7848  342]\n",
        " [2717 5279]]\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/metrics.py:1744: FutureWarning: In the future, providing two `labels` values, as well as `average` will average over those labels. For now, please use `labels=None` with `pos_label` to evaluate precision, recall and F-score for the positive label only.\n",
        "  FutureWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/metrics.py:1744: FutureWarning: In the future, providing two `labels` values, as well as `average` will average over those labels. For now, please use `labels=None` with `pos_label` to evaluate precision, recall and F-score for the positive label only.\n",
        "  FutureWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/metrics.py:1744: FutureWarning: In the future, providing two `labels` values, as well as `average` will average over those labels. For now, please use `labels=None` with `pos_label` to evaluate precision, recall and F-score for the positive label only.\n",
        "  FutureWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/metrics.py:1744: FutureWarning: In the future, providing two `labels` values, as well as `average` will average over those labels. For now, please use `labels=None` with `pos_label` to evaluate precision, recall and F-score for the positive label only.\n",
        "  FutureWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/metrics.py:1744: FutureWarning: In the future, providing two `labels` values, as well as `average` will average over those labels. For now, please use `labels=None` with `pos_label` to evaluate precision, recall and F-score for the positive label only.\n",
        "  FutureWarning)\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Evaluate ROC\n",
      "\n",
      "import numpy as np\n",
      "from scipy import interp\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from sklearn import svm, datasets\n",
      "from sklearn.metrics import roc_curve, auc\n",
      "from sklearn.cross_validation import StratifiedKFold\n",
      "\n",
      "# Convert dataset\n",
      "x = np.array(x_list)\n",
      "y = np.array(y_list)\n",
      "\n",
      "\n",
      "# Classification and ROC analysis\n",
      "\n",
      "# Run classifier with cross-validation and plot ROC curves\n",
      "cv = StratifiedKFold(y, n_folds=4)\n",
      "random_state = np.random.RandomState(0)\n",
      "classifier = svm.SVC(C=10, kernel='linear', probability=True,\n",
      "                     random_state=random_state)\n",
      "\n",
      "mean_tpr = 0.0\n",
      "mean_fpr = np.linspace(0, 1, 100)\n",
      "all_tpr = []\n",
      "\n",
      "for i, (train, test) in enumerate(cv):\n",
      "    probas_ = classifier.fit(x[train], y[train]).predict_proba(x[test])\n",
      "    # Compute ROC curve and area the curve\n",
      "    fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])\n",
      "    mean_tpr += interp(mean_fpr, fpr, tpr)\n",
      "    mean_tpr[0] = 0.0\n",
      "    roc_auc = auc(fpr, tpr)\n",
      "    plt.plot(fpr, tpr, lw=1, label='ROC fold %d (area = %0.2f)' % (i, roc_auc))\n",
      "\n",
      "plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Luck')\n",
      "\n",
      "mean_tpr /= len(cv)\n",
      "mean_tpr[-1] = 1.0\n",
      "mean_auc = auc(mean_fpr, mean_tpr)\n",
      "plt.plot(mean_fpr, mean_tpr, 'k--',\n",
      "         label='Mean ROC (area = %0.2f)' % mean_auc, lw=2)\n",
      "\n",
      "plt.xlim([-0.05, 1.05])\n",
      "plt.ylim([-0.05, 1.05])\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "plt.title('Receiver operating characteristic example')\n",
      "plt.legend(loc=\"lower right\")\n",
      "plt.show()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn import svm\n",
      "from sklearn.metrics import precision_recall_curve\n",
      "from sklearn.metrics import average_precision_score\n",
      "from sklearn.cross_validation import train_test_split\n",
      "# Eval PR-Curve\n",
      "# Split into training and test\n",
      "random_state = np.random.RandomState(0)\n",
      "X_train, X_test, y_train, y_test = train_test_split(x_list, y_list, test_size=.3,\n",
      "                                                    random_state=random_state)\n",
      "\n",
      "# Run classifier\n",
      "classifier = svm.SVC(C=10, kernel='linear', class_weight={1:0.6},\n",
      "                     random_state=random_state)\n",
      "y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
      "\n",
      "# Compute Precision-Recall and plot curve\n",
      "precision, recall, thresh = precision_recall_curve(y_test,y_score)\n",
      "average_precision = average_precision_score(y_test, y_score)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot Precision-Recall vs Thresh\n",
      "plt.clf()\n",
      "plt.plot(thresh, precision[0:-1], label='Precision curve')\n",
      "plt.plot(thresh, recall[0:-1], label='Recall curve')\n",
      "plt.xlabel('Thresh')\n",
      "plt.ylabel('Precision-Recall')\n",
      "plt.ylim([0.0, 1.05])\n",
      "plt.xlim([0.0, 1.0])\n",
      "plt.xticks(np.arange(0, 1.05, 0.05))\n",
      "plt.yticks(np.arange(0, 1.05, 0.05))\n",
      "plt.title('Precision-Recall example: AUC={0:0.2f}'.format(average_precision))\n",
      "plt.legend(loc=\"lower left\")\n",
      "plt.show()\n",
      "\n",
      "# Plot Precision-Recall curve\n",
      "plt.clf()\n",
      "plt.plot(recall, precision, label='Precision-Recall curve')\n",
      "plt.xlabel('Recall')\n",
      "plt.ylabel('Precision')\n",
      "plt.ylim([0.0, 1.05])\n",
      "plt.xlim([0.0, 1.0])\n",
      "plt.xticks(np.arange(0, 1.05, 0.05))\n",
      "plt.yticks(np.arange(0, 1.05, 0.05))\n",
      "plt.title('Precision-Recall example: AUC={0:0.2f}'.format(average_precision))\n",
      "plt.legend(loc=\"lower left\")\n",
      "plt.show()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Train/Save\n",
      "clf = svm.SVC(kernel='linear', C=10, class_weight={1:0.6})\n",
      "clf.fit(x_list, y_list)\n",
      "import cPickle\n",
      "with open('pickled/classifier.pickle', 'wb') as f:\n",
      "    cPickle.dump(clf, f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}